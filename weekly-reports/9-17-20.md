# Report Week 9/17/20
## Activities/Accomplishments and Concepts/Lessons Learned
* looked into best choice for desktop computer and monitor to be used during research this semester and in the lab
* played around with Unreal Engine some more
* began Udemy course on making hyper-realistic outdoor environments in unreal engine
* read research paper 'Learning to Learn without Gradient Descent by Gradient Descent'
## Issues/Problems
* again ran into problems using UE on my machine
* I was unfamiliar with many of the optimization and learning methods in the research paper
## Plans
* continue with Udemy course
* create simple simulation of robot moving around space in UE
* look more into meta-learning methods for transfer learning from simulation
## Article Summaries
[Learning to Learn Without Gradient Descent by Gradient Descent](http://papers.nips.cc/paper/6461-learning-to-learn-by-gradient-descent-by-gradient-descent.pdf)

This research article outlined the methods of approaching the meta-learning problem using RNNs to produce an algorithm for global black-box optimization. One of the most common methods for black-box optimization is Bayesian optimization using a Gaussian Process (GP), however a major downside of this method when applied to search strategies is its cubic complexity. Two types of RNNs are used in the learning to learn approach taken by the researchers to be contrasted with Bayesian optimization in the task of global optimization of black-box functions. Long-short-term memory networks (LSTMs) and differentiable neural computers (DNCs) are used during meta learning and optimized by gradient descent on many differentiable functions generated with a GP. The RNN uses information about previous queries and function evaluations, and stochastic gradient descent is performed after taking derivatives of the loss with respect to RNN parameters after multiple sequential steps are taken while feeding forward through the network. Within its hidden states, the RNN stores information on observations, and deciding what to store is part of the learning process. Multiple worker nodes can be utilized by the RNN in order to evaluate functions in parallelâ€”empirical results demonstrate this is not only faster, but matches performance of the network without this method. 

Perhaps most relevant to our project, an example of reinforcement learning consisting of a 2D simulation of a falling particle in a physical system between repellers with two parameters is shown to be best executed when handled with neural networks. In light of this empirical evidence of the robust performance of RNNs when used for meta-learning, we may consider to approach our problem of transfer learning from a simulation environment by first developing a network which is able to optimize learning from any general simulation, and use that network to optimize the parameters of the one which we are to use to transfer the learning of our robot from simulation in Unreal Engine to the physical world.
